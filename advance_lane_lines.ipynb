{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "calib_images=[]\n",
    "    \n",
    "def calibrate_Camera_Images(images,chess_coordinate_x,chess_coordinate_y):\n",
    "    # Step through the list and search for chessboard corners\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((chess_coordinate_y*chess_coordinate_x,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:chess_coordinate_x,0:chess_coordinate_y].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    obj_points = [] # 3d points in real world space\n",
    "    img_points = [] # 2d points in image plane.\n",
    "    calib_images_array=[]\n",
    "    \n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (chess_coordinate_x,chess_coordinate_y),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            obj_points.append(objp)\n",
    "            img_points.append(corners)\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (chess_coordinate_x,chess_coordinate_y), corners, ret)\n",
    "            #plt.figure()\n",
    "            #plt.imshow(img)\n",
    "            calib_images_array.append(img)\n",
    "            #cv2.imshow('img',img)\n",
    "            #cv2.waitKey(500)\n",
    "    #cv2.destroyAllWindows()\n",
    "    return obj_points,img_points,calib_images_array\n",
    "\n",
    "chess_coordinate_x=9\n",
    "chess_coordinate_y=6\n",
    "objpoints,imgpoints,calib_images=calibrate_Camera_Images(images,chess_coordinate_x,chess_coordinate_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in calib_images:\n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply a distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#calculate distortion values\n",
    "img = cv2.imread('../camera_cal/calibration1.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"calibration.p\", \"wb\" ) )\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "f.subplots_adjust(hspace = .2, wspace=.05)\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = cv2.imread('../test_images/test1.jpg')\n",
    "def undistort(img):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "def undist_color_transform_binary(img):\n",
    "    img_test=undistort(img)\n",
    "    hls_test=cv2.cvtColor(img_test,cv2.COLOR_BGR2HLS)\n",
    "    s_channel=hls_test[:,:,2]\n",
    "    thresh = (90, 255)\n",
    "    binary = np.zeros_like(s_channel)\n",
    "    binary[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    return binary\n",
    "binary=undist_color_transform_binary(img_test)\n",
    "plt.imshow(binary,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test = cv2.imread('../test_images/test1.jpg')\n",
    "img_size = (img_test.shape[1], img_test.shape[0])\n",
    "offset=100\n",
    "src = np.float32([(610,410),(700,410),(1100,700),(220,700)])\n",
    "#dst = np.float32([[offset, offset], [img_size[0]-offset, offset],[img_size[0]-offset, img_size[1]-offset],[offset, img_size[1]-offset]])\n",
    "\n",
    "#M=cv2.getPerspectiveTransform(src,dst)\n",
    "#warped = cv2.warpPerspective(undistor_image,M,img_size)\n",
    "\n",
    "# Visualize unwarp\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img_test)\n",
    "x = [src[0][0],src[2][0],src[3][0],src[1][0],src[0][0]]\n",
    "y = [src[0][1],src[2][1],src[3][1],src[1][1],src[0][1]]\n",
    "ax1.plot(x, y, color='#22bb44',linewidth=4, zorder=2)\n",
    "ax1.set_title('test image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the curvature of the lane and vehicle position with respect to center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
